\chapter{Low-mode averaging}
\label{ch:p2:lma}

\readit{2}

% \worktodo{
% * Separate chapter LMA
%     * 4p from intro
%     * spectral prop from 2pt
%     * V2 problem
%     * X-term problem
% }


\tldr{LMA original and usages}
This chapter introduces the variance reduction method of low-mode averaging~\cite{Neff_2001,DeGrand_2004,Giusti_2004} (LMA) and some of its many variants which had a large influence in this thesis.
We start with the general propagator decomposition (\cref{sec:lma:prop:decomp}), followed by an individual discussion of the emerging terms related to the high modes (\cref{sec:lma:rr}), low modes (\cref{sec:lma:ee}) and the crossing term (\cref{sec:lma:x}).
The chapter ends with an analysis of its problems in terms of the appearance of a quadratic volume scaling on large lattices and challenges that emerge when evaluating the pieces introduced through the propagator decomposition (\cref{sec:lma:summary}).


LMA consists of decomposing the quark propagator $\prop=D^{-1}$ into a truncated spectral decomposition and a remainder, defined precisely in the following.
%\worktodo{Tim: Defined precisely below}
%The method is used widely in the field for quantities suffering from the signal-to-noise ratio problem in the long distance.
The method has been widely used in the field for observables with poor signal in the long distance sensitive to low modes.
Examples are the LO-HVP~\cite{bmw_2024,Kuberski_2023,Aubin:2022hgm,Bazavov:2024eou,RBC_2024} and HLbL~\cite{Lin:2024khg} contributions to the muon $g-2$ or derived quantities~\cite{ExtendedTwistedMass:2025tpc}, baryon three-point functions~\cite{Yang:2015zja,Ohki:2012jyg} and masses \cite{Bali:2010se}, nucleon charges~\cite{Yamanaka:2018uud}, reweighting of the RHMC~\cite{Kuberski:2023zky}, decay constants~\cite{Bali:2014pva}, low energy couplings~\cite{Bernardoni:2011kd}, form factors~\cite{JLQCD:2009ofg} and many more.
Clearly, the method is only beneficial if the volume average over the deflated subspace captures the large distance behavior of the observable and one can afford a numerical determination of the low-mode subspace.
%Clearly, the method is only beneficial if the majority of the noise \worktodo{Tim: What noise????? The noise introduced by *not* computing the translation average.} comes from the low-mode contribution and one can afford a numerical determination of the linear-in-volume scaling low-mode subspace.

\section{Spectral decomposition}
\label{sec:lma:prop:decomp}

In its simplest form, LMA introduces an improved estimator for \cref{eq:G:corr:connected} using the spectral decomposition of the Hermitian Dirac operator,
\begin{equation}
Q = \sum_{n=0}^{12V-1} \lambda_{n} \evec_{n} \evec_{n}^{\dagger} \;,
\qquad
Q = \gamma^{5} D \;,
\qquad
Q^{\dagger} = Q \;,
\end{equation}
into an orthonormal eigenbasis $\mathcal{B} = \{ \evec_n \}_{n=0}^{12V-1}$ with
\begin{equation}
Q \evec_{n} = \lambda_{n} \evec_{n} \;,
\qquad
\evec_{n}^{\dagger} \evec_{m} = \delta_{nm} \;,
\end{equation}
with real eigenvalues $\lambda_{n} \in \mathbb{R}$.
The same decomposition holds for the propagator
\begin{equation} \label{eq:prop:all-to-all}
\propxy{x}{y} = \sum_{n=0}^{12V-1} \frac{1}{\lambda_{n}} \fieldx{\evec_{n}}{x} \fieldx{\evec_{n}^{\dagger}}{y} \gamma^{5} \;,
\end{equation}
where the $\gamma^{5}$ at the end is because $\prop = Q^{-1} \gamma^{5}$.
This is actually a singular value decomposition\footnote{To be more precise, $S = \sum_n \sigma_n \psi_{n} \phi_{n}^{\dagger}$, where $\sigma_n = \frac{1}{\lvert \lambda_{n} \rvert}$ are the singular values with $\psi_{n} = \text{sign}(\lambda_n) \evec_{n}$ and $\phi_{n} = \gamma^{5} \evec_{n}$ the left and right singular vectors, respectively.}.
Analogously, we emphasize just as \cref{eq:prop:pt-to-all} is an exact point-to-all propagator (no approximation involved), the above is an exact all-to-all propagator.

In its current state, this propagator is not appropriate for numerical computations, because the full eigen-decomposition into all $12V$ modes is numerically inaccessible.
Although we can truncate the sum in \cref{eq:prop:all-to-all} and only take the $\cNc \ll 12 V$ modes with lowest magnitude eigenvalues, \ie the largest $\frac{1}{\lambda_{n}}$.
These are the modes that contribute most to the propagator and to the variance~\cite{DeGrand_2004}.
To do this, we define an orthogonal projector to the space of the $\cNc$ lowest modes as
\begin{equation} \label{eq:lma:projector}
P = \sum_{n=0}^{\cNc-1} \evec_n \evec_n^{\dagger} \;,
\qquad
P^{2} = P = P^{\dagger} \;.
\end{equation}
The full all-to-all propagator is then decomposed into two terms
\begin{equation} \label{eq:prop:lma}
\prop
= \underbrace{\sum_{n=0}^{\cNc-1}
  \frac{1}{\lambda_{n}} \evec_{n} \evec_{n}^{\dagger} \gamma^{5}}_{=\prop_e}
+ \underbrace{(1-P) Q^{-1} \gamma^{5}}_{=\prop_r} \;,
\end{equation}
one contribution along the low eigenmode space $\prop_e$ and a remainder $\prop_r$.
We note that this decomposition is an exact equality.

The two-point connected correlator \cref{eq:G:corr:connected} has two slots for propagators.
We can either plug \cref{eq:prop:lma} in only one slot or in both of them.
Both options result in different valid estimators.
We will continue with the latter and since the propagator is now a sum of two terms, we obtain four individual terms for the correlator,
\begin{equation}
G^{\text{conn}}(t)
= G_{ee}^{\text{conn}}(t)
+ G_{er}^{\text{conn}}(t)
+ G_{re}^{\text{conn}}(t)
+ G_{rr}^{\text{conn}}(t) \;.
% - \frac{a^{3}}{3 \lvert \Omega \rvert}
% \sum_{y \in \Omega}
% \sum_{\vect{x}} \;
% \sum_{k=1}^{3}
% \tr \left[
%   \prop(t+y_0, \vect{x}|y) \gamma_k \prop(y|t+y_0, \vect{x}) \gamma_k
% \right].
\end{equation}
The terms can be worked out using properties of the $\gamma$-matrices
\begin{align}
\{\gamma^{5}, \gamma_{\mu}\} &= 0 \;,        &  (\gamma^{5})^{2} &= \id \;, \\
\gamma_{\mu}^{\dagger} &= \gamma_{\mu} \;,   &  (\gamma^{5})^{\dagger} &= \gamma^{5} \;.
\end{align}
Since their evaluation schemes differ quite substantially, we will individually discuss them in the following.

\section{The rest-rest term}
\label{sec:lma:rr}

The rest-rest term is the simplest one in the decomposition.
It is just the standard form \cref{eq:G:corr:connected}, but with $\prop$ being replaced by the projected $\tilde{\prop} = (1-P)\prop$,
\begin{equation}
G^{\text{conn}}(t) =
- \frac{a^{3}}{3 \lvert \Omega \rvert}
\sum_{y \in \Omega}
\sum_{\vect{x}} \;
\sum_{k=1}^{3}
\tr \left\{
  \opxy{\tilde{\prop}}{t+y_0, \vect{x}}{y} \gamma_k \opxy{\tilde{\prop}}{y}{t+y_0, \vect{x}} \gamma_k
\right\} \;.
\end{equation}
If enough low modes were deflated, this term does not significantly contribute to the variance in the large distance.
It can then be estimated using standard estimators, for instance point- or stochastic time-diluted sources as introduced in \cref{sec:point:prop,sec:stochastic:prop}.
Evaluation of this term differs only slightly from the original correlator.
Still, linear systems of equation of the type $D \psi = \eta$ have to be solved, but followed by projecting the solution with $1-P$.

\section{The eigen-eigen term}
\label{sec:lma:ee}

The eigen-eigen term can be worked out as
\begin{multline} \label{eq:Gconn:eigen-eigen}
G_{ee}^{\text{conn}}(t)
% = - \frac{a^{3}}{3 V}
% \sum_{k=1}^{3}
% \sum_{n,m=0}^{\cNc-1} \frac{1}{\lambda_{n} \lambda_{m}}
% \sum_{y_0=0}^{L_0-1} \;
% \sprod{
%   \evec_{n}^{(y_0)}
% }{
%   \gamma^{5}
%   \gamma_k
%   \evec_{m}^{(y_0)}
% } \\
% \cdot
% \sprod{
%   \evec_{m}^{(t+y_0)}
% }{
%   \gamma^{5}
%   \gamma_k
%   \evec_{n}^{(t+y_0)}
% }.
= - \frac{a^{3}}{3 V}
\sum_{k=1}^{3}
\sum_{n,m=0}^{\cNc-1} \frac{1}{\lambda_{n} \lambda_{m}}
\sum_{\vect{x},y} \;
\sprod{
  \fieldx{\evec_{n}}{y}
}{
  \gamma^{5}
  \gamma_k
  \fieldx{\evec_{m}}{y}
} \\
\cdot
\sprod{
  \fieldx{\evec_{m}}{t+y_0, \vect{x}}
}{
  \gamma^{5}
  \gamma_k
  \fieldx{\evec_{n}}{t+y_0, \vect{x}}
} \;,
\end{multline}
where the $\sprod{\cdot}{\cdot}$ denotes the standard spinor product on the lattice Hilbert space.
Since the eigenmodes are defined on every lattice point, we can easily perform a full volume average of this contribution $\lvert \Omega \rvert = V$ as seen in the prefactor.
This is characteristic to this type of estimator but also crucial, because now the eigen-eigen term is at the minimal variance (its gauge noise level) and its variance cannot be lowered further for a fixed gauge config\footnote{Without employing multi-level sampling schemes.}.
Due to the exact averaging over the subspace of low modes, this class of estimators is known under the name low-mode \emph{averaging}.
All deflated low modes have to be in memory at the same time, because the above is a all-to-all contraction in the eigenvector indices $n$ and $m$.
We will later see that it can be written as a trace of objects living in the eigenspace.

\section{The cross-term}
\label{sec:lma:x}

The two crossing terms, rest-eigen and eigen-rest, show some symmetry,
\begin{align}
G_{er}^{\text{conn}}(t) &=
\frac{a^{3}}{3 L^{3} \lvert \mathcal{T} \rvert}
\sum_{y_0 \in \mathcal{T}} \;
\sum_{n=0}^{\cNc-1} \; \frac{1}{\lambda_{n}}
\sum_{k=1}^{3} \;
\sprod{
  \tilde{\prop}
  \gamma_k
  \evec_{n}^{\tslice{y_0}}
}{
  \gamma^{5}
  \gamma_k
  \evec_{n}^{\tslice{t+y_0}}
} \;, \\
G_{re}^{\text{conn}}(t) &=
\frac{a^{3}}{3 L^{3} \lvert \mathcal{T} \rvert}
\sum_{y_0 \in \mathcal{T}} \;
\sum_{n=0}^{\cNc-1} \frac{1}{\lambda_{n}} \;
\sum_{k=1}^{3} \;
\sprod{
  \gamma^{5}
  \gamma_k
  \evec_{n}^{\tslice{t+y_0}}
}{
  \tilde{\prop}
  \gamma_k
  \evec_{n}^{\tslice{y_0}}
} \;,
\end{align}
where $\tilde{\prop} = (1-P) \prop$ and we have introduced the time-diluted modes
\begin{equation}
\fieldx{\evec_{n}^{\tslice{t}}}{x} =
\begin{cases}
  \fieldx{\evec_{n}}{x} & \text{if } x_0 = t \;, \\
  0 & \text{otherwise} \;.
\end{cases} 
\end{equation}
They were defined such that the original mode can be recovered by summing over all times and they are mutually orthogonal with respect to the time dilution but not orthonormal anymore
\begin{equation}
\evec_{n} = \sum_{t=0}^{L_0-1} \evec_{n}^{\tslice{t}} \;,
\qquad
\sprod{\evec_{n}^{\tslice{t}}}{\evec_{m}^{\tslice{s}}} \sim \delta_{ts} \;. % not \delta_{nm} ???
\end{equation}
Both cross-terms are in general complex valued, but they are complex conjugates of each other and thus we only need to estimate one of them
\begin{align}
G_{\cross}^{\text{conn}}(t)
&= G_{er}^{\text{conn}}(t) + G_{re}^{\text{conn}}(t) \\
&= 2 \Re{G_{er}^{\text{conn}}(t)} \;.
\end{align}

Clearly the cross-term is expensive to calculate exactly, since we need to solve the Dirac equation on every time-diluted mode for every $\gamma$-matrix we want to evaluate the correlator for, \ie solve the systems
\begin{equation}
D \psi = (1-P) \gamma_k \evec_{n}^{\tslice{t}} \;,
\end{equation}
for all $k = 1,2,3$, $t \in \stime$ and $n = 0, \ldots, \cNc-1$.
In total $3 \cNc L_0$ solves to calculate the piece exactly!
Many improved estimators will not include the whole time extend, all $\gamma$-matrices or all modes but a subset of them.
Additionally, many LMA-scenarios employ heavily truncated solves on subsets for the above and correct the bias regularly with differences of high precision and truncated solves to obtain an unbiased estimator~\cite{bmw_2017,Kuberski_2023}.
Alternatively one can introduce a stochastic estimator for the cross-term~\cite{lynch2023,fermi_2023}.
In all variants of LMA, this term comes at a large associated cost overhead due to its non-negligible variance contribution.
We will call this the \emph{cross-term problem}.
%However, the problem related to the expensive evaluation of the cross-term due to its non-negligible variance contribution, we will call the \emph{cross-term problem}.
%We called this the \emph{cross-term problem}.

Another noteworthy variant of LMA goes under the name of all-mode averaging (AMA)~\cite{Blum_2012,CAA,Blum_2015,RBC_2018}.
It comes with a slightly different propagator decomposition
\begin{equation}
\prop
= \underbrace{\prop - \prop_{\text{AMA}}}_{\prop_{\text{r}}}
+ \underbrace{\sum_{n=0}^{\cNc-1} \frac{1}{\lambda_n} \evec_n \evec_n^{\dagger} \gamma^{5}
+ P_n(Q) P \gamma^{5}}_{\prop_{\text{AMA}}} \;.
\end{equation}
Here $P_n(Q)$ is a polynomial in $Q$ usually obtained from an implicitly generated polynomial of a truncated solve (TSM)~\cite{Bali_2009} preconditioned by the eigenmodes and $P$ is defined as in \cref{eq:lma:projector}.
Here, the TSM does not need bias correction, since the above is a exact decomposition, irrespective of the truncation scheme.
For this estimator, it is also possible to set $\cNc=0$ \cite{Blum_2012}.
The terms involving $\prop_{r}$ are treated with very few sources, since they do not contribute much to the overall variance.
Nevertheless, AMA merely moves the problem of the cross-term into the term including $\prop_{\text{AMA}}$ without solving it at its root.
The polynomial's purpose is to extend the averaging from low modes to all modes, hence the name \emph{all}-mode averaging.
However, in all scenarios the cost of this term poses one of the major limiters of LMA, a problem which we aim to solve in the remainder of this part.

\section{Summary}
\label{sec:lma:summary}

We have introduced a new class of estimators for the connected LO-HVP contribution based on low-mode deflation.
The propagator is decomposed into a truncated spectral sum and a remainder.
The two-point correlator involving the spectral sum can be easily volume averaged pushing its variance to its gauge variance, whereas the variance on the remaining terms is considered small.
Unfortunately, this breaks down as lattice size increases, because determining low modes scaling with lattice volume becomes computationally prohibitive.
% We mentioned limits of LMA in terms of the two related problems: the $V^2$-problem (number of low modes required is proportional to the lattice volume) and the cross-term problem (remaining cross piece still contributes non-negligibly to the overall variance).

Clearly the cost and the effectiveness of LMA and variants critically depend on the number of low modes $\cNc$ where the spectral sum is truncated -- an algorithmic parameter not easy to chose properly.
Due to Banks and Casher\cite{banks1980}, $\cNc$ needs to be proportional to the lattice volume, a condition hard to satisfy on large lattices.
We called this the \emph{$V^{2}$-problem}.
It refers to the asymptotic quadratic cost scaling that recurrently arises when increasing the lattice size, specifically but not exclusively in the context of LMA.

We encounter two competing motives.
First, the number of low modes should be large enough to capture all the long distance behavior of the correlator and ensure that the cross-term contributes negligibly to the overall variance.
Second, the number of low modes should be small enough to keep the cross-term computationally affordable.
A non-trivial interplay between computational cost and variance reduction.

%In order to achieve a fair variance reduction we want to drive the number of deflated low modes as high as we can afford.
%On the other hand, the cost of the eigensolver and of the cross-term increase proportional.
%It is not feasible anymore on large lattices to drive the number of eigenmodes so high to suppress the variance on the cross-term such that its evaluation is cheap.
Many variants of LMA try to circumvent the cross-term problem by reducing the cost of its estimator.
Still, these variants do not solve the problem at its root, which is the $V^2$-problem.
Revisiting current high-precision determinations of the connected LO-HVP of the muon $g-2$, the numbers of \numrange{1000}{6000} low modes used in these studies~\cite{Djukanovic:2024cmq,RBC_2024,bmw_2024,Aubin:2022hgm} are not high enough to suppress the cross-term variance; they are mere thresholds of what is affordable.
An often unmentioned issue is the immense memory footprint of $\bigO(1000)$ low modes that have to be in memory all at the same time, sometimes even driving the required node count of the job into the bad strong scaling region.

The next chapter will generalize the deflation of low modes to the deflation of arbitrary subspaces.

%\tldr{V2 problem}
%The method usually comes with two tasks, both of which are computationally expensive.
%First, one has to determine a certain number of eigenmodes of the Hermitian or the non-Hermitian Dirac operator.
%This number heavily depends on the lattice volume, the physical quantity of interest and the variance reduction goal.
%Obviously the more modes involved, the better the outcome.
% The number of low modes required for constant variance reduction is proportional to the lattice volume, because the size of the low-mode subspace is proportional to the lattice volume~\cite{banks1980}.
% Therefore, the computational work to determine the low-mode subspace scales at least quadratic in the lattice volume, which we will refer to as \emph{$V^{2}$-problem}~\cite{Luescher2007}.
% This fact makes LMA on large-scale physical point lattices prohibitively expensive.
%On recent high-precision determinations of the HVP contribution to the muon $g-2$ this number is driven to the limit of affordability; \numrange{1000}{6000}~\cite{Djukanovic:2024cmq,RBC_2024,bmw_2024,Aubin:2022hgm} with varying satisfaction.

%\tldr{X-term problem}
%Second, when plugging the decomposition of the propagator into two-point correlators, we obtain a cross-term mixing low- and high-mode contributions, usually called \emph{rest-eigen} term.
%If the number of low modes is not sufficiently high\footnote{The numbers mentioned in the previous paragraph are \emph{not} high enough.}, the cross-term still contributes non-negligibly to the large distance variance -- an issue which we will refer to as \emph{cross-term problem}.
%The cost of evaluating this term is proportional to the number of low modes.

%Many extensions of LMA have been proposed mainly to deal with the cross-term problem.
%All-mode averaging (AMA) employs many cheap low-precision solves, corrected with a few high-precision solves~\cite{Blum_2012,CAA,RBC_2018,Blum_2015}.
%The truncated solver method (TSM) very similarly uses many heavily truncated solves, corrected with a few high-precision solves~\cite{bmw_2017,Kuberski:2023zky}.
%In refs.~\cite{fermi_2023,lynch2023} the cross-term together with the high-mode (rest-rest) term is evaluated stochastically.
