%!TEX root = ../../../thesis.tex

\chapter{CI/CD}
\label{ch:p1:cicd}

This section describes the continuous integration testing and deployment pipeline of openQxD's development repository\cite{gitlab:openqxd-devel}. At the time of writing this thesis the repository is private. As part of the goals of the PASC project\cite{pasc:project} as thus as part of this thesis, we employ CI/CD paradigms into the development workflow of openQxD.

\section{Continuous integration}

New features, bug-fixes or code changes enter the codebase by means of a separate branch and a corresponding merge-request, which is reviewed, tested and finally merged into the master branch. By this the master branch stays clean and functional, such that at every point in time one can release a new version of the software by just taking the newest commit to the master branch as version tag.

\section{Continuous testing}
\label{sec:cicd:testing}

We decided on a testing strategy as follows:

\begin{itemize}
    \item For continuous testing, the master branch is tested on a daily basis overnight at 1 am (CET) on local resources at ETH. This runs the GitLab pipeline described in \cref{sec:cicd:pipeline:gitlab}.
    \item For continuous testing, the master branch is tested every 3 months on GH200 machines at CSCS. This runs the CSCS pipeline described in \cref{sec:cicd:pipeline:cscs}.
    \item For continuous integration, every commit into every open merge-request is automatically tested on local resources at ETH. This runs the GitLab pipeline described in \cref{sec:cicd:pipeline:gitlab}.
    \item{For continuous integration, open merge-requests can be tested by triggering the CSCS pipeline manually. This runs the CSCS pipeline described in \cref{sec:cicd:pipeline:cscs}. The pipeline can be trigger by commenting on a merge-request with
    \begin{minted}[linenos=false]{text}
cscs-ci run default
    \end{minted}
    This will invoke the webhook that triggers CSCS services to run the pipeline. A short time after commenting \worktodo{TODO}...
    }
\end{itemize}

see figure \cref{fig:external} blabla.

\begin{figure}
    \centering
    \includesvg[inkscapelatex=false,scale=1.2]{\dir/img/external4}
    %\includegraphics[]{\dir/img/external.tiff}
    \caption{BLAbla.}
    \label{fig:external}
\end{figure}

Thus there are two pipelines. One that runs on via GitLab on local resources at ETH, and one that runs via CSCS on the GH200 nodes at CSCS. Both pipelines are independent and completely detached from each other, they may run in parallel or not.

\subsection{GitLab pipeline}
\label{sec:cicd:pipeline:gitlab}

The entrypoint for this pipeline is in the openQxD-devel repository\cite{gitlab:openqxd-devel} under \code{.gitlab-ci.yml} directly in the root. Parts of this pipeline may run on official GitLab runners (if time is available). The testing jobs require the runner to expose one or more local GPUs into the docker image to be able to run CUDA code. Clearly the official GitLab runners do not provide GPUs. We registered a local machine at ETH which specifications
\begin{itemize}
    \item 2x AMD EPYC 9124 16-Core Processor
    \item 8x NVIDIA GeForce A2000 (12 GB, CUDA-architecture \code{sm\_86})
    \item 1.5 TB main memory
\end{itemize}
as an additional runner for this pipeline. The machine has 8 GPUs which makes it ideal for various testing scenarios, like lattices with C$^\star$-boundaries in all $3$ spatial directions which require a minimum of 8 ranks.

The pipeline consists of three stages; prepare, build and test. In general the stages depends on each other, although there are jobs in the build stage which depend on nothing. They will be discussed separately in the following.

\subsubsection{The prepare stage}

\emph{All jobs in the prepare stage may run on official GitLab runners.} As the name suggests, this stage has some preparatory jobs, whose artifacts will be exposed to subsequent jobs. Here, in the job called \code{download-quda} we download a copy of QUDA from its official GitHub repository \cite{github:quda} via \code{git clone} and expose it as artifact. We download the latest developments committed to the \code{develop} branch, i.e. their CI branch. All subsequent tests that depend on this job, will use the newest available developments of QUDA. Therefore we will notice breaking changes immediately.

\subsubsection{The build stage}
\label{sec:cicd:pipeline:gitlab:build}

\emph{All jobs in the build stage may run on official GitLab runners.} However, this stage consists of a matrix of jobs that compiles openQxD with various combinations of compilers and MPI implementations. This can be easily extended to cover missing combinations. At the time of writing, we cover compilers gcc-10, gcc-11, gcc-12, gcc-13, gcc-14, clang-18 and two MPI libraries Open MPI\cite{online:openmpi} and MPICH\cite{online:mpich}. These compile-jobs search through the whole repository. In every directory they find a \code{Makefile}, they will call \code{make}. This makes sure that all programs and modules in the project are compiled. These jobs do not depend on any other job and will fail if one of the commands fails. Their job names have the pattern
\begin{minted}[linenos=false]{text}
build-openqxd/<mpi>:<version>-<compiler>:<version>
\end{minted}
where \code{<mpi>} is replaced by either \code{openmpi} or \code{mpich} and \code{<compiler>} with \code{gcc} or \code{clang}.

The other build jobs may depend on the prepare stage or on other build jobs. The jobs with pattern
\begin{minted}[linenos=false]{text}
build-quda/cuda:<version>-<cuda_arch>
\end{minted}
build QUDA for the CUDA architecture given by \code{<cuda\_arch>} using certain CUDA versions given by \code{<version>}. They can also easily be extended to cover more versions and architectures.

Finally the jobs to build openQxD against QUDA have the pattern
\begin{minted}[linenos=false]{text}
build-openqxd/quda-checks/<cuda_arch>-<bcs>
\end{minted}
They depend on the previous build jobs that build QUDA with the appropriate \code{<cuda\_arch>}. The placeholder \code{<bcs>} is substituted with the boundary conditions of the lattice we want to test against. Currently we run tests on two lattices, see \cref{tab:cicd:ensembles}. Thus we compile openQxD on a process grid of 1x2x2x2 for these two lattices. Also these jobs can be extended to other lattices.

\begin{table}[t]
  \centering
  \begin{tabular}{ccccc}
    \toprule
    {ensemble}&
    {$L_0 \times L^3$}&
    {$m_{\pi}$ [MeV]}&
    {boundary conditions}&
    {\# configs} \\
    \midrule
    D5d         & $48 \times 24^3$ & 439 & periodic    & 2 \\
    A360a50b324 & $64 \times 32^3$ & 360 & C$^{\star}$ in xyz directions & 2 \\
    \bottomrule
  \end{tabular}
  \caption{\label{tab:cicd:ensembles}%
    Ensembles used in the CI/CD pipeline. The periodic lattice D5d is taken from Ref.~\cite{online:cls}, whereas the C$^{\star}$ lattice is taken from Ref.~\cite{RCstar22}.}
\end{table}

\subsubsection{The test stage}
\label{sec:cicd:pipeline:gitlab:test}

\emph{All jobs in the test stage may \textbf{not} run on official GitLab runners, they require a GPU and thus may only run on the local resource.} Jobs in this stage depend on the build jobs that build openQxD against QUDA discussed at the end of the previous section. They may not run if previous jobs failed. They have names as
\begin{minted}[linenos=false]{text}
test-openqxd/quda-check<N>/<cuda_arch>-<bcs>
\end{minted}
where \code{<N>} is the number of the check we run, i.e. the check corresponds to \code{devel/quda/check<N>.c} which was built in the previous stage. We briefly discuss the binaries:
\begin{itemize}
  \item \code{devel/quda/check1}: Checks the indexing functions of fields, i.e. the arrays \code{ipt[VOLUME]} and \code{iup[VOLUME][4]} (see \code{main/README.global}) against the pure function implementations in QUDA, \code{openQCD\_qudaIndexIpt} and \code{openQCD\_qudaIndexIup} respectively. Afterwards the transfers of gauge field to QUDA and back are executed and compared two each other. Finally the plaquette on QUDA and on openQCD are computed and compared. This is done only with the $SU(3)$-valued gauge field, even if a QCD+QED lattice is given as input.
  \item \code{devel/quda/check2}: This check performs a host-to-device and device-to-host transfer of a spinor field compares the two on the host. Further the norm function as well as the gamma matrix applications are compared to make sure the gamma basis is the same. Finally we compare the Wilson-Clover Dirac operator by acting on a random spinor field on both openQxD and QUDA and compare them.
  \item \code{devel/quda/check3}: Here we have implemented acceptance tests of solvers in QUDA. This means we call the solver in QUDA according to its configuration from the input file provided to the executable. The relative residual of the yielded solution is checked explicitely against the Dirac operator in openQxD and compared to the desired relative residual from the solver configuration.
  \item \code{devel/quda/check4}: Consists of a check of the eigensolver of QUDA. This is currently not tested.
\end{itemize}

For the check of the solvers, \code{check3}, we decided to verify certain interface functionalities apart from a correct solution. We run on $2$ gauge configurations, $2$ different flavors and $3$ different solvers. The input files can be found under \code{ci/input/*.in}. That implies $12$ actual calls to a solver in QUDA. We test multiple gauge configs and flavors to verify if the interface properly updates gauge and clover fields and is aware of changing parameters due to changing flavors. For instance, if on a QCD+QED C$^{\star}$-lattice we change the value of the inverse charge, \code{qhat}, we have to retransfer the gauge field to QUDA, because $\hat{q}$ appears in the $U(1)$-phase of the $U(3)$-valued gauge field, see \worktodo{equation}. This has to be triggered automatically by the interface code when changing parameters.

Additionally, we test $3$ different solvers. One is a multigrid solver similar to one that would be used in a production run. The second solver is also a multigrid solver to check if multiple different instances of multigrid do not interfere with each other. Finally, a BiCGSTAB solver without any preconditioning is tested to check if another type of solver can be interfaced successfully.

In order to test on multiple gauge configurations, we need them available in the job. This is achieved by enabling the package registry on GitLab and uploading the gauge configs as \code{tar.gz} archives. These can be found in the GitLab project under \code{Deploy -> Package Registry}. The test jobs download the archive corresponding to the lattice they run on, control the MD5 sums and run the checks.

This concludes the discussion of the GitLab pipeline.

\subsection{CSCS pipeline}
\label{sec:cicd:pipeline:cscs}

This pipeline may only run on the official GH200 nodes at CSCS and is associated with an account having compute quota on the Daint Alps vCluster. \emph{Running job in this pipeline consumes nodehours of the associated account.} The entrypoint for this pipeline is in the openQxD-devel repository\cite{gitlab:openqxd-devel} under \code{ci/cscs\_default\_pipeline.yml}. The pipeline consists of two stages; build and test.

\subsubsection{The build stage}

In this stage, we build and install the newest develop version of QUDA using Spack\cite{Gamblin_The_Spack_Package_2015} directly into a so called uenv\cite{online:cscs:uenv} image. For this to work, we need QUDA as a Spack package, see \cref{sec:building:quda:spack}. Using this machinery, the descriptive build job for QUDA is very simple:
\begin{minted}[]{yaml}
build-quda/uenv/daint-gh200:
  stage: build
  extends: .uenv-builder-daint-gh200
  variables:
    UENV_RECIPE: ci/uenv-recipes/quda/daint-gh200
\end{minted}
We see that it simply extends the runner \code{.uenv-builder-daint-gh200}, which is provided by CSCS and included a few lines above. We also include a local file for global definitions, \code{ci/include/definitions.yml}. Together with the global definitions we have some important variables that change the behavior of the aforementioned job:
\begin{itemize}
  \item \code{UENV\_NAME}: specifies the name of the uenv image we want to build.
  \item \code{UENV\_VERSION}: specifies the version of the uenv image we want to build.
  \item \code{UENV\_RECIPE}: points to a uenv recipe.
\end{itemize}
The uenv recipe is a descriptive way on how to specify an environment in terms of its software dependencies. It consists of several YAML-files:
\begin{itemize}
  \item \code{config.yaml}: Description of the package, its name, brief description in a sentence and which Spack version to use.
  \item \code{compilers.yaml}: Description of the compilers for bootstrapping and the compiler to use when compiling all software and dependencies. This works as follows: the system compiler (usually a very old gcc) is used to compiler the bootstrap compiler (usually a newer gcc). Then the bootstrap compiler is used to compile the compiler we want to use (usually a recent gcc).
  \item{\code{environments.yaml}: Description of the environment, i.e. \code{gcc-env.specs} list all Spack specs that should be compiled and installed, \code{gcc-env.mpi} is dictated by CSCS to be \code{cray-mpich} with CUDA enabled (CUDA-aware MPI), \code{gcc-env.variants} adds Spack variant modifiers to all packages that support them in the spec list. \code{gcc-env.views} configures the available views in the image. The view \code{spack} is always added to the image. The view \code{modules} is added if in \code{config.yaml} we set \code{modules: true}. The \code{openqxd} view is added in the \code{post-install} script. The specs hold a spec for QUDA
  \begin{minted}[linenos=false]{text}
  quda@experimental +openqcd +multigrid +wilson +clover
  \end{minted}
  which builds and installs QUDA with the interface code. This is currently installed with the additional package under \code{repo/} describing the QUDA build and install procedures. \worktodo{change to develop}}
  \item \code{modules.yaml}: Description of the \code{modules} view if it was enabled in \code{config.yaml}. This is for legacy behavior if we want to generate Tcl\cite{online:tcl} or Lmod\cite{github:lmod} modules from the software given in the \code{gcc-env.specs} in \code{environments.yaml}. These can be loaded once the uenv is started.
  \item \code{post-install}: A post installation script that currently adds the \code{openqxd} view which specifies the environment variables required to build openQxD.
  \item \code{repo/}: An additional repo path to add to Spack. Under this path currently lies the QUDA package description until it is available in the official Spack repositories.
\end{itemize}

However, this builds a uenv image containing QUDA built for the GH200 nodes with CUDA architecture \code{sm\_90} using the correct MPI implementation provided by CSCS. If this stage was successful, the test stage is being executed.

\subsubsection{The test stage}

In the same way as for the GitLab pipeline (\cref{sec:cicd:pipeline:gitlab}) we run the checks in \code{devel/quda} using the same lattices (\cref{tab:cicd:ensembles}), and input files. All that differs is that we run all checks sequentially in one job. We do not discuss the individual checks again and refer the reader to \cref{sec:cicd:pipeline:gitlab:test} for more details. However, there are two test jobs, one for the periodic and one for the C$^{\star}$ lattice. Both run with 8 ranks, thus 2 GH200 nodes, each 4 GPUs. The specification of a GH200 nodes is
\begin{itemize}
    \item 4x NVIDIA Grace (72 Neoverse V2 cores) processor
    \item 4x NVIDIA H100 (96 GB HBM3, CUDA-architecture \code{sm\_90})
    \item 4x 128 GB LPDDR 5X RAM
\end{itemize}

\section{Continuous deployment}

For continuous deployment, open merge-requests can be deployed by triggering the CSCS deploy pipeline manually. This runs the CSCS deploy pipeline described in \cref{sec:cd:pipeline:cscs}. The pipeline can be trigger by commenting on a merge-request with
\begin{minted}[linenos=false]{text}
cscs-ci run deploy
\end{minted}
in the same way as described in \cref{sec:cicd:testing} for the testing.

\subsection{CSCS deploy pipeline}
\label{sec:cd:pipeline:cscs}

The entrypoint for this pipeline is in the openQxD-devel repository\cite{gitlab:openqxd-devel} under \code{ci/cscs\_deploy\_pipeline.yml}. The pipeline consists of only one stage; deploy.

\subsubsection{The deploy stage}

This stage currently consists of only one job that deploys the previously built uenv image to the CSCS registry. When deployed a user logged in to Daint Alps, can just pull and start the image and find an already compiled version of QUDA with all required environment variables set to build openQxD against QUDA, see \cref{sec:building:openqxd} for more details on building openQxD and \cref{lst:openqxd:env_vars} for the required environment variables and \cref{sec:building:uenv} for more information on how to run the uenv.
